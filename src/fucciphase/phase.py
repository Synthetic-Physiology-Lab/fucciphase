import logging
from enum import Enum
from typing import Literal

import dtaidistance.preprocessing
import numpy as np
import pandas as pd
from dtaidistance.dtw import warping_amount
from dtaidistance.subsequence.dtw import subsequence_alignment
from scipy import interpolate, stats

from .sensor import FUCCISensor
from .utils import (
    check_channels,
    check_thresholds,
    get_norm_channel_name,
    get_time_distortion_coefficient,
)

logger = logging.getLogger(__name__)

# Type alias for signal processing mode
SignalMode = Literal["signal", "derivative", "both"]


class NewColumns(str, Enum):
    """Columns generated by the analysis.


    Attributes
    ----------
    CELL_CYCLE_PERC : str
        Unique cell cycle percentage value
    PHASE : str
        Phase of the cell cycle
    """

    CELL_CYCLE_PERC_DTW = "CELL_CYCLE_PERC_DTW"
    CELL_CYCLE_PERC = "CELL_CYCLE_PERC"
    PHASE = "PHASE"
    DISCRETE_PHASE_MAX = "DISCRETE_PHASE_MAX"
    DISCRETE_PHASE_BG = "DISCRETE_PHASE_BG"
    DISCRETE_PHASE_DIFF = "DISCRETE_PHASE_DIFF"
    DTW_DISTORTION = "DTW_DISTORTION"
    DTW_DISTORTION_REL = "DTW_DISTORTION_REL"
    DTW_DISTANCE = "DTW_DISTANCE"
    DTW_WARPING = "DTW_WARP"
    REL_DTW_WARPING = "DTW_WARP_REL"

    @staticmethod
    def cell_cycle() -> str:
        """Return the name of the unique intensity column."""
        return NewColumns.CELL_CYCLE_PERC.value

    @staticmethod
    def phase() -> str:
        """Return the name of the phase column."""
        return NewColumns.PHASE.value

    @staticmethod
    def cell_cycle_dtw() -> str:
        """Return the name of the cell cycle percentage column."""
        return NewColumns.CELL_CYCLE_PERC_DTW.value

    @staticmethod
    def discrete_phase_max() -> str:
        """Return the name of the discrete phase column."""
        return NewColumns.DISCRETE_PHASE_MAX.value

    @staticmethod
    def discrete_phase_bg() -> str:
        """Return the name of the discrete phase column."""
        return NewColumns.DISCRETE_PHASE_BG.value

    @staticmethod
    def discrete_phase_diff() -> str:
        """Return the name of the discrete phase column."""
        return NewColumns.DISCRETE_PHASE_DIFF.value

    @staticmethod
    def dtw_distortion() -> str:
        """Return the name of the DTW distortion."""
        return NewColumns.DTW_DISTORTION.value

    @staticmethod
    def dtw_distortion_norm() -> str:
        """Return the name of the DTW distortion."""
        return NewColumns.DTW_DISTORTION_REL.value

    @staticmethod
    def dtw_distance() -> str:
        """Return the name of the DTW distance."""
        return NewColumns.DTW_DISTANCE.value

    @staticmethod
    def dtw_warping_amount() -> str:
        """Return the name of the DTW warping amount."""
        return NewColumns.DTW_WARPING.value

    @staticmethod
    def rel_dtw_warping_amount() -> str:
        """Return the name of the relative DTW warping amount."""
        return NewColumns.REL_DTW_WARPING.value


def generate_cycle_phases(
    df: pd.DataFrame,
    channels: list[str],
    sensor: FUCCISensor,
    thresholds: list[float],
    estimate_percentage: bool = False,
) -> None:
    """Add cell-cycle phase (and optionally percentage) columns to the dataframe.

    The phase is determined using thresholds on the normalized channel
    intensities, assuming a FUCCI-like sensor. For each row (spot) in the
    dataframe, this function:

    1. Checks that normalized intensity columns exist for all requested channels.
    2. Uses :func:`estimate_cell_phase_from_max_intensity` to assign a
       discrete phase label based on whether each channel is ON/OFF.
    3. Optionally calls :func:`estimate_cell_cycle_percentage` to estimate
       a continuous cell-cycle percentage from the intensities and the
       discrete phase.

    The thresholds per channel must be between 0 and 1 and are interpreted
    as fractions of the maximum intensity in that channel (e.g. 0.1 means
    “10% of max”).

    Parameters
    ----------
    df : pandas.DataFrame
        Dataframe with columns holding normalized intensities.
    channels : List[str]
        Names of normalized channels to use for phase estimation.
    sensor : FUCCISensor
        FUCCI sensor with phase-specific information.
    thresholds : List[float]
        Thresholds (0-1) used to separate phases.
    estimate_percentage : bool, optional
        If True, also estimate a continuous cell-cycle percentage.


    Raises
    ------
    ValueError
        If the number of thresholds is not 2
    ValueError
        If the phases are not unique
    ValueError
        If the thresholds are not between 0 and 1, one excluded
    """
    # sanity check: check that the normalized channels are present
    norm_channel_names = []
    for channel in channels:
        norm_channel_name = get_norm_channel_name(channel)
        if norm_channel_name not in df.columns:
            raise ValueError(
                f"Column {get_norm_channel_name(channel)} not found, call "
                f"normalize_channel({channel}) on the dataframe."
            )
        norm_channel_names.append(norm_channel_name)

    # check that all channels are present
    check_channels(sensor.fluorophores, channels)

    # compute discrete phases based on normalized intensities
    estimate_cell_phase_from_max_intensity(
        df,
        norm_channel_names,
        sensor,
        background=[0] * sensor.fluorophores,
        thresholds=thresholds,
    )

    # name of phase column
    phase_column = NewColumns.discrete_phase_max()
    # optionally compute continuous cell-cycle percentages
    if estimate_percentage:
        estimate_cell_cycle_percentage(df, norm_channel_names, sensor, phase_column)


def estimate_cell_cycle_percentage(
    df: pd.DataFrame, channels: list[str], sensor: FUCCISensor, phase_column: str
) -> None:
    """Estimate cell cycle percentage from intensity pairs.

    For each row in the dataframe, this function reads the normalized
    intensities in ``channels`` together with the discrete phase label in
    ``phase_column`` and queries the sensor for an estimated cell-cycle
    percentage. The result is stored in the ``CELL_CYCLE_PERC`` column.

    Parameters
    ----------
    df : pandas.DataFrame
        Dataframe with normalized intensity columns and a phase column.
    channels : List[str]
        Names of normalized intensity columns for each fluorophore.
    sensor : FUCCISensor
        FUCCI sensor used to map intensities and phase to cycle percentage.
    phase_column : str
        Name of the column storing discrete phase labels.
    """
    percentages = []
    # iterate through data frame
    for _, row in df.iterrows():
        intensities = [row[channel] for channel in channels]
        phase = row[phase_column]
        percentage = sensor.get_estimated_cycle_percentage(phase, intensities)
        percentages.append(percentage)

    # TODO add inplace to dataframe
    # df[NewColumns.cell_cycle()] = pd.Series(percentages, dtype=float)
    df[NewColumns.cell_cycle()] = percentages


def estimate_cell_phase_from_max_intensity(
    df: pd.DataFrame,
    channels: list[str],
    sensor: FUCCISensor,
    background: list[float],
    thresholds: list[float],
) -> None:
    """Estimate discrete cell-cycle phase by thresholding normalized intensities.

    For each channel, the background value is subtracted from the mean
    intensity. The resulting intensities are normalized by the maximum
    mean intensity observed in that channel. A channel is considered ON
    if its normalized intensity exceeds the corresponding threshold.

    The ON/OFF pattern across channels is then mapped to a discrete phase
    using the sensor model.

    Parameters
    ----------
    df : pandas.DataFrame
        Dataframe containing the normalized intensity columns.
    channels : List[str]
        Names of normalized intensity columns.
    sensor : FUCCISensor
        FUCCI sensor with phase analysis information.
    background : List[float]
        Single background value per channel.
    thresholds : List[float]
        Thresholds (0-1) used to separate phases.

    Raises
    ------
    ValueError
        If required channels are missing or if background/threshold lists
        are inconsistent with the number of channels.
    """
    # sanity check: check that channels are present
    for channel in channels:
        if channel not in df.columns:
            raise ValueError(
                f"Column {channel} not found, provide correct input parameters."
            )

    if len(channels) != len(background):
        raise ValueError("Provide one background value per channel.")

    check_channels(sensor.fluorophores, channels)
    check_thresholds(sensor.fluorophores, thresholds)

    phase_markers_list: list[pd.Series[bool]] = []
    for channel, bg_value, threshold in zip(
        channels, background, thresholds, strict=True
    ):
        # get intensities and subtract background
        intensity = df[channel] - bg_value
        # threshold channels to decide if ON / OFF (data is in list per spot)
        phase_markers_list.append(intensity > threshold * intensity.max())
    phase_markers_list_tilted = np.array(phase_markers_list).T

    # store phases
    phase_names = []
    for phase_markers in phase_markers_list_tilted:
        phase_names.append(sensor.get_phase(phase_markers))
    # TODO check pd.Series issue
    df[NewColumns.discrete_phase_max()] = phase_names


def estimate_cell_phase_from_background(
    df: pd.DataFrame,
    channels: list[str],
    sensor: FUCCISensor,
    background: list[float],
    thresholds: list[float],
) -> None:
    """Add a column in place to the dataframe with the estimated phase of the cell
    cycle, where the phase is determined by comparing the channel intensities to
    the respective background intensities.

    The provided factors are used to decide if a channel is switched on (ON).
    If the intensity exceeds the background level times the factor, the channel
    is ON. Hence, the factors should be greater than 0.


    Parameters
    ----------
    df: pd.DataFrame
        Dataframe with a CELL_CYCLE_PERC column
    channels: List[str]
        Names of channels
    sensor: FUCCISensor
        FUCCI sensor with specific phase analysis information
    background: List[float]
        Single value per channel representing background
    thresholds: List[float]
        Thresholds to separate phases

    Raises
    ------
    ValueError
        If the dataframe does not contain the normalized channels.
    """
    # sanity check: check that channels are present
    for channel in channels:
        if channel not in df.columns:
            raise ValueError(
                f"Column {channel} not found, provide correct input parameters."
            )

    if len(channels) != len(background):
        raise ValueError("Provide one background value per channel.")

    check_channels(sensor.fluorophores, channels)

    phase_markers_list: list[pd.Series[bool]] = []
    for channel, bg_value, threshold in zip(
        channels, background, thresholds, strict=True
    ):
        intensity = df[channel]
        # threshold channels to decide if ON / OFF (data is in list per spot)
        phase_markers_list.append(intensity > threshold * bg_value)
    phase_markers_list_tilted = np.array(phase_markers_list).T

    # store phases
    phase_names = []
    for phase_markers in phase_markers_list_tilted:
        phase_names.append(sensor.get_phase(phase_markers))
    df[NewColumns.discrete_phase_bg()] = pd.Series(phase_names, dtype=str)  # add as str


def _process_channel(
    series: np.ndarray,
    signal_mode: SignalMode,
    smooth: float,
    channel_name: str = "",
) -> list[np.ndarray]:
    """Process a single channel according to the signal mode.

    Parameters
    ----------
    series : np.ndarray
        The input signal array.
    signal_mode : SignalMode
        Processing mode: "signal", "derivative", or "both".
    smooth : float
        Smoothing factor for differencing.
    channel_name : str, optional
        Channel name for warning messages.

    Returns
    -------
    list[np.ndarray]
        List of processed arrays. Length 1 for "signal" or "derivative",
        length 2 for "both" (signal first, then derivative).
    """
    results = []

    if signal_mode in ("signal", "both"):
        results.append(series.copy())

    if signal_mode in ("derivative", "both"):
        try:
            diff = dtaidistance.preprocessing.differencing(series, smooth=smooth)
        except ValueError:
            if channel_name:
                logger.warning(
                    "Smoothing failed for channel %s, continuing without smoothing",
                    channel_name,
                )
            diff = dtaidistance.preprocessing.differencing(series)
        results.append(diff)

    return results


def _compute_output_length_offset(signal_mode: SignalMode) -> int:
    """Return the offset to add to query length for output array size.

    When using derivatives, the output is 1 element shorter, so we need
    to add 1 to get back to the original track length.

    Parameters
    ----------
    signal_mode : SignalMode
        The signal processing mode.

    Returns
    -------
    int
        Offset to add: 1 if derivative is used, 0 otherwise.
    """
    if signal_mode in ("derivative", "both"):
        return 1
    return 0


# flake8: noqa: C901
def estimate_percentage_by_subsequence_alignment(
    df: pd.DataFrame,
    dt: float,
    channels: list[str],
    reference_data: pd.DataFrame,
    smooth: float = 0.1,
    penalty: float = 0.05,
    track_id_name: str = "TRACK_ID",
    minimum_track_length: int = 10,
    use_zscore_norm: bool = True,
    signal_mode: SignalMode = "derivative",
    use_derivative: bool | None = None,
) -> None:
    """Use subsequence alignment to estimate percentage.

    Parameters
    ----------
    df: pd.DataFrame
        DataFrame with tracks
    dt: float
        Timestep between frames in hours
    channels: List[str]
        List of channels to be matched with reference data
    reference_data: pd.DataFrame
        Containing reference intensities over time
    smooth: float
        Smoothing factor, see dtaidistance documentation
    penalty: float
        Penalty for DTW algorithm, enforces diagonal warping path
    track_id_name: str
        Name of column with track IDs
    minimum_track_length: int
        Only estimate phase for tracks longer than this
    use_zscore_norm: bool
        Use z-score normalization before differencing curves
        Probably not needed if intensities of reference and measured
        curve are similar
    signal_mode: SignalMode
        Signal processing mode:
        - "signal": use raw signal only
        - "derivative": use derivative only (default, for baseline independence)
        - "both": use both signal and derivative as features
    use_derivative: bool | None
        Deprecated. Use signal_mode instead. If provided, overrides signal_mode
        for backward compatibility (True -> "derivative", False -> "signal").
    """
    # Handle backward compatibility with use_derivative parameter
    if use_derivative is not None:
        import warnings

        warnings.warn(
            "use_derivative is deprecated, use signal_mode instead",
            DeprecationWarning,
            stacklevel=2,
        )
        signal_mode = "derivative" if use_derivative else "signal"

    if "time" not in reference_data:
        raise ValueError("Need to provide time column in reference_data.")
    if "percentage" not in reference_data:
        raise ValueError("Need to provide percentage column in reference_data.")

    if not set(channels).issubset(reference_data.columns):
        raise ValueError("Provide channel names in reference_data.")

    # interpolate reference curve
    time_scale = reference_data["time"].to_numpy()
    interpolation_functions = {}
    for channel in channels:
        interpolation_functions[channel] = interpolate.interp1d(
            time_scale, reference_data[channel].to_numpy()
        )
    f_percentage = interpolate.interp1d(
        time_scale, reference_data["percentage"].to_numpy()
    )

    num_time = int(time_scale[-1] / dt)
    new_time_scale = np.linspace(0, dt * num_time, num=num_time + 1)
    actual_dt = new_time_scale[1] - new_time_scale[0]
    if not np.isclose(dt, actual_dt):
        raise ValueError(
            f"Time scale mismatch: requested dt={dt}, but computed dt={actual_dt}. "
            "Check that the reference data time scale is compatible with "
            "the requested timestep."
        )

    # reference curve in time scale of provided track
    percentage_ref = f_percentage(new_time_scale)

    processed_series = []
    for channel in channels:
        series = interpolation_functions[channel](new_time_scale)
        if use_zscore_norm:
            series = stats.zscore(series)
        # if all values are the same, we zero to avoid numerical issues
        if np.all(np.isnan(series)):
            series = np.zeros_like(series)

        channel_features = _process_channel(series, signal_mode, smooth, channel)
        processed_series.extend(channel_features)

    # For "both" mode, trim signal features to match derivative length
    if signal_mode == "both":
        min_len = min(len(s) for s in processed_series)
        processed_series = [s[-min_len:] for s in processed_series]
        # Also trim the percentage reference to match
        percentage_ref = percentage_ref[-min_len:]

    series = np.array(processed_series)
    series = np.swapaxes(series, 0, 1)

    df.loc[:, NewColumns.cell_cycle_dtw()] = np.nan

    track_ids = df[track_id_name].unique()
    for track_id in track_ids:
        track_df = df.loc[df[track_id_name] == track_id]
        # the algorithm does not work for short tracks
        if len(track_df) < minimum_track_length:
            # insert NaN
            new_percentage = np.full(len(track_df), np.nan)
            df.loc[df[track_id_name] == track_id, NewColumns.cell_cycle_dtw()] = (
                new_percentage[:]
            )
            continue

        # find percentages if track is long enough
        queries = track_df[channels].to_numpy()

        processed_queries = []
        for idx in range(len(channels)):
            query_series = queries[:, idx].copy()
            if use_zscore_norm:
                query_series = stats.zscore(query_series)
            # if all values are the same, we zero to avoid numerical issues
            if np.all(np.isnan(query_series)):
                query_series = np.zeros_like(query_series)

            channel_features = _process_channel(query_series, signal_mode, smooth)
            processed_queries.extend(channel_features)

        # For "both" mode, trim signal features to match derivative length
        if signal_mode == "both":
            min_len = min(len(q) for q in processed_queries)
            processed_queries = [q[-min_len:] for q in processed_queries]

        query = np.array(processed_queries)
        query = np.swapaxes(query, 0, 1)

        sa = subsequence_alignment(query, series, penalty=penalty)
        best_match = sa.best_match()
        length_offset = _compute_output_length_offset(signal_mode)
        new_percentage = np.zeros(query.shape[0] + length_offset)

        # Handle empty path case
        if len(best_match.path) == 0:
            new_percentage[:] = np.nan
        else:
            for p in best_match.path:
                new_percentage[p[0]] = percentage_ref[p[1]]
            if p[1] + 1 < len(percentage_ref):
                last_percentage = p[1] + 1
            else:
                last_percentage = p[1]
            new_percentage[-1] = percentage_ref[last_percentage]
        # save estimated cell cycle percentages
        df.loc[df[track_id_name] == track_id, NewColumns.cell_cycle_dtw()] = (
            new_percentage[:]
        )
        # save DTW distance
        df.loc[df[track_id_name] == track_id, NewColumns.dtw_distance()] = (
            best_match.value
        )

        # Handle empty path case for DTW metrics
        if len(best_match.path) == 0:
            df.loc[df[track_id_name] == track_id, NewColumns.dtw_distortion()] = np.nan
            df.loc[
                df[track_id_name] == track_id, NewColumns.dtw_distortion_norm()
            ] = np.nan
            df.loc[
                df[track_id_name] == track_id, NewColumns.dtw_warping_amount()
            ] = np.nan
            df.loc[
                df[track_id_name] == track_id, NewColumns.rel_dtw_warping_amount()
            ] = np.nan
        else:
            _, distortion_score, _, _ = get_time_distortion_coefficient(
                best_match.path
            )
            # save DTW distortion
            df.loc[df[track_id_name] == track_id, NewColumns.dtw_distortion()] = (
                distortion_score
            )
            df.loc[df[track_id_name] == track_id, NewColumns.dtw_distortion_norm()] = (
                distortion_score / len(track_df)
            )

            # save DTW warping amount
            df.loc[df[track_id_name] == track_id, NewColumns.dtw_warping_amount()] = (
                warping_amount(best_match.path)
            )

            df.loc[
                df[track_id_name] == track_id, NewColumns.rel_dtw_warping_amount()
            ] = (warping_amount(best_match.path) / len(track_df))
